{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65cc9503-9fce-4ffb-b809-67bd94def736",
   "metadata": {},
   "source": [
    "# __Activation Functions__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2d3630f-8d48-40d4-b062-63cf27fdd7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cdb9e6-12fe-4d41-b4c5-a4411a6bfb1a",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn-images-1.medium.com/max/800/0*lo8wlkwReDcXkts0.png\" width =\"700\" height=700 ></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2086a8-e2d5-48bb-bb4c-32eb68da97a5",
   "metadata": {},
   "source": [
    "### Source for activation function reference\n",
    "\n",
    "url = \"https://patrickhoo.wixsite.com/diveindatascience/single-post/2019/06/13/activation-functions-and-when-to-use-them\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb4ea4e-5040-430d-a0b1-e3fbdf557c81",
   "metadata": {},
   "source": [
    "### Sigmoid Function\n",
    "\n",
    "1. The sigmoid function is one fo the most used activation functions also called as S-curve\n",
    "2. It scales the value between 0 - 1\n",
    "3. Differential meaning that we can find the slope of the curve at any two points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0f36fbf-7207-484c-aa9c-64c0b00c7c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7582902-015e-4570-b98e-c1167f5341c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.73105858, 0.88079708, 0.95257413])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.array([1,2,3])\n",
    "sigmoid(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfeeda80-b7dc-44ae-a586-a62bfc829de2",
   "metadata": {},
   "source": [
    "## Tanh function\n",
    "\n",
    "1. A hyperbolic tangent(tanh) function outputs value between -1 and +1\n",
    "2. Differential, meaning that we can find the slope of the curve at any point\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acd37264-c9b6-4411-aa3c-53835aef9787",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh(x):\n",
    "    numerator = 1 - np.exp(-2*x)\n",
    "    denominator = 1 + np.exp(-2*x)\n",
    "    return numerator/denominator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7205566f-12e0-40b6-a29a-6c52bd85e3c5",
   "metadata": {},
   "source": [
    "## ReLU (Rectified Linear Unit)\n",
    "\n",
    "1. outputs values between 0 and infinity\n",
    "2. Problem: Dying ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67b01508-7eae-4964-97a6-d509b5e8b990",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(x):\n",
    "    return 0 if x<0 else x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4531c415-6b41-4c62-9e2d-c8ce779fcba8",
   "metadata": {},
   "source": [
    "## Leaky ReLU or PReLU (Parametric ReLU function)\n",
    "\n",
    "1. Leaky ReLU is a variant of ReLU function that solves the dying ReLU problem\n",
    "2. Instead of converting every negative input to zero, it has a small slope for a negative value\n",
    "3. If we set alpha as parameter rather than default value, we call it as Parametric ReLU\n",
    "4. If a random value is set to alpha then it is called __Randomized ReLU Function__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d43376a-6e69-4a12-a225-fca98dc9bdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def leakyReLU(x, alpha=0.01):\n",
    "    return alpha*x if x<0 else x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c954ad-f6f3-4c9a-a49c-6742af6c4694",
   "metadata": {},
   "source": [
    "## Exponention Linear Unit (ELU) Function\n",
    "\n",
    "1. like leaky ReLU has a small slpe for negative value\n",
    "2. But instead of having a straight line it has a log curve instead of converting every negative input to zero, it has a small slope for a negative value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d57a6edc-8203-46ec-ad3f-15ce17fe57db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ELU(x, alpha=0.01):\n",
    "    return alpha*(np.exp(x)-1) if x<0 else x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef32165-0e6e-48b5-8528-1b01d708be6b",
   "metadata": {},
   "source": [
    "## Swish function\n",
    "1. The swish function is recently introduced activation function by Google\n",
    "2. Unlike other activation functions, which are monotonic, swish is a non-monotonic function, which means it is neither always non-increasing nor non-decreasing\n",
    "3. It provides better performance than ReLU\n",
    "4. Self gated activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20efd31c-cf19-4c10-8b8d-898881274757",
   "metadata": {},
   "source": [
    "<img src=\"https://forums.fast.ai/uploads/default/original/2X/2/210bd227a378be10a1fe7ea50466e131c8a2d5eb.png\" width =\"800\" height=800 ></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed0f3b1e-577c-444f-9151-69dc12765f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def swish(x,beta):\n",
    "    return 2*x*sigmoid(beta*x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddd2524-edbc-475c-b7b0-bc7c8445f937",
   "metadata": {},
   "source": [
    "# all these funcitons are used in hidden layers and not in output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5638fb2-7170-497a-8c19-3928e8b654a9",
   "metadata": {},
   "source": [
    "# For multiclass classification we need softmax function  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e681637c-7aa1-4d4c-99e3-e5bb8960554e",
   "metadata": {},
   "source": [
    "## Softmax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c87986c-6d57-4c80-8581-7fedb5c00fe7",
   "metadata": {},
   "source": [
    "<img src=\"data:image/png;base64,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\"></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85faf90e-0192-4fc0-a0b8-19c9aa77d18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return np.exp(x)/np.exp(x).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ecad2608-1e0a-45e1-b79a-98636749324d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation:\n",
    "    \n",
    "    def __init__(self,x, activation='sigmoid', alpha=0.01, beta=None):\n",
    "        self.activation = activation\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.x = x\n",
    "        self.result = self._result(self.x, alpha=self.alpha, beta=self.beta)\n",
    "        \n",
    "    def _result(self, x, alpha=0.01, beta=None):\n",
    "        assert (self.activation == 'swish' and self.beta !=None), \"Please provide a beta value for swish activation\"\n",
    "        return getattr(self, self.activation)()\n",
    "        \n",
    "    def sigmoid(self):\n",
    "        return 1/(1+np.exp(-self.x))\n",
    "    \n",
    "    def tanh(self):\n",
    "        numerator = 1 - np.exp(-2*self.x)\n",
    "        denominator = 1 + np.exp(-2*self.x)\n",
    "        return numerator/denominator\n",
    "    \n",
    "    def ReLU(self):\n",
    "        return 0 if self.x<0 else self.x\n",
    "    \n",
    "    def leakyReLU(self):\n",
    "        return self.alpha*self.x if self.x<0 else self.x\n",
    "    \n",
    "    def ELU(self):\n",
    "        return self.alpha*(np.exp(self.x)-1) if self.x<0 else self.x\n",
    "    \n",
    "    def swish(self):\n",
    "        return 2*self.x*sigmoid(self.beta*self.x)\n",
    "    \n",
    "    def softmax(self):\n",
    "        return np.exp(self.x)/np.exp(self.x).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "27033c22-0247-4c2a-a733-cb9f63df8099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.14819826799214"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Activation(4,activation='swish',beta=0.3).result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
